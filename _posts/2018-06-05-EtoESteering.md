---
layout: post
title: "Prediction of Steering Angles"
date: 2018-06-05
excerpt: "Using Keras to predict steering angles from images of the road"
tag:
- Python
- Neural Network
- Numpy
- Keras
- Tesla
project: true
comments: false
---
<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_psxzh1e2gb2o-6>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-6,decimal) ". "}ol.lst-kix_psxzh1e2gb2o-6.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-6 0}.lst-kix_psxzh1e2gb2o-6>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-6}.lst-kix_psxzh1e2gb2o-0>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-0}.lst-kix_psxzh1e2gb2o-4>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-4,lower-latin) ". "}.lst-kix_psxzh1e2gb2o-8>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-8,lower-roman) ". "}.lst-kix_psxzh1e2gb2o-3>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-3,decimal) ". "}.lst-kix_psxzh1e2gb2o-7>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-7,lower-latin) ". "}.lst-kix_psxzh1e2gb2o-5>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-5,lower-roman) ". "}ol.lst-kix_psxzh1e2gb2o-3.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-3 0}ol.lst-kix_psxzh1e2gb2o-0.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-0 0}.lst-kix_mxunidxk0446-3>li:before{content:"\0025cf  "}.lst-kix_mxunidxk0446-2>li:before{content:"\0025a0  "}.lst-kix_mxunidxk0446-4>li:before{content:"\0025cb  "}.lst-kix_psxzh1e2gb2o-7>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-7}ol.lst-kix_psxzh1e2gb2o-2.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-2 0}.lst-kix_mxunidxk0446-0>li:before{content:"\0025cf  "}.lst-kix_mxunidxk0446-8>li:before{content:"\0025a0  "}.lst-kix_mxunidxk0446-1>li:before{content:"\0025cb  "}.lst-kix_mxunidxk0446-7>li:before{content:"\0025cb  "}.lst-kix_mxunidxk0446-6>li:before{content:"\0025cf  "}.lst-kix_psxzh1e2gb2o-4>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-4}.lst-kix_mxunidxk0446-5>li:before{content:"\0025a0  "}.lst-kix_psxzh1e2gb2o-1>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-1}ol.lst-kix_psxzh1e2gb2o-1.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-1 0}.lst-kix_psxzh1e2gb2o-3>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-3}ol.lst-kix_psxzh1e2gb2o-8.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-8 0}ol.lst-kix_psxzh1e2gb2o-5.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-5 0}ul.lst-kix_mxunidxk0446-0{list-style-type:none}ul.lst-kix_mxunidxk0446-1{list-style-type:none}ul.lst-kix_mxunidxk0446-2{list-style-type:none}ul.lst-kix_mxunidxk0446-3{list-style-type:none}.lst-kix_psxzh1e2gb2o-2>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-2}ul.lst-kix_mxunidxk0446-4{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-3{list-style-type:none}ul.lst-kix_mxunidxk0446-5{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-2{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-7.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-7 0}ul.lst-kix_mxunidxk0446-6{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-1{list-style-type:none}ul.lst-kix_mxunidxk0446-7{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-0{list-style-type:none}.lst-kix_psxzh1e2gb2o-5>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-5}ul.lst-kix_mxunidxk0446-8{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-7{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-6{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-5{list-style-type:none}.lst-kix_psxzh1e2gb2o-8>li{counter-increment:lst-ctn-kix_psxzh1e2gb2o-8}ol.lst-kix_psxzh1e2gb2o-4{list-style-type:none}ol.lst-kix_psxzh1e2gb2o-4.start{counter-reset:lst-ctn-kix_psxzh1e2gb2o-4 0}.lst-kix_psxzh1e2gb2o-0>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-0,decimal) ". "}ol.lst-kix_psxzh1e2gb2o-8{list-style-type:none}.lst-kix_psxzh1e2gb2o-2>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-2,lower-roman) ". "}.lst-kix_psxzh1e2gb2o-1>li:before{content:"" counter(lst-ctn-kix_psxzh1e2gb2o-1,lower-latin) ". "}ol{margin:0;padding:0}table td,table th{padding:0}.c9{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:54pt;border-top-color:#000000;border-bottom-style:solid}.c18{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:414pt;border-top-color:#000000;border-bottom-style:solid}.c24{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:269.2pt;border-top-color:#000000;border-bottom-style:solid}.c31{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:2.2pt;width:54pt;border-top-color:#000000;border-bottom-style:solid}.c4{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:2.2pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c11{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:3pt;width:468pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:2.2pt;width:414pt;border-top-color:#000000;border-bottom-style:solid}.c3{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:middle;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;border-left-style:solid;border-bottom-width:0pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify;height:11pt}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:justify}.c23{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c30{color:#000000;text-decoration:none;vertical-align:baseline;font-size:8pt;font-style:normal}.c27{color:#000000;text-decoration:none;vertical-align:baseline;font-size:20pt;font-style:normal}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:11pt}.c10{color:#000000;text-decoration:none;vertical-align:baseline;font-size:12pt;font-style:normal}.c25{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c28{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c6{font-weight:700;font-family:"Times New Roman"}.c5{font-weight:400;font-family:"Times New Roman"}.c21{margin-left:36pt;padding-left:0pt}.c8{margin-left:72pt;padding-left:0pt}.c19{padding:0;margin:0}.c17{height:18pt}.c29{margin-left:144pt}.c22{height:0pt}.c26{font-style:italic}.c15{height:7pt}.c13{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c28"><p class="c0"><span class="c6 c27">End to End Steering</span></p><a id="t.1aebe24dda1b56316fca09844ec7bf63e4290b0d"></a><a id="t.0"></a><table class="c25"><tbody><tr class="c22"><td class="c11" colspan="1" rowspan="1"><p class="c0 c13"><span class="c5 c10"></span></p></td></tr></tbody></table><p class="c0 c13"><span class="c5 c30"></span></p><a id="t.9d29e370ca10eb9d0fd41f77a76360d1b1965252"></a><a id="t.1"></a><table class="c25"><tbody><tr class="c17"><td class="c9" colspan="1" rowspan="1"><p class="c0"><span class="c7 c6">To:</span></p></td><td class="c18" colspan="2" rowspan="1"><p class="c0"><span class="c5">Clint Staley</span><span class="c1">, Professor, Department of Computer Science, Cal Poly SLO</span></p></td></tr><tr class="c17"><td class="c9" colspan="1" rowspan="1"><p class="c0"><span class="c7 c6">From:</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c0"><span class="c1">Journey McDowell &nbsp; &nbsp; &nbsp; | &nbsp; &nbsp; &nbsp; Paul Rothhammer-Ruiz &nbsp; &nbsp;|</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c0"><span class="c1">Chris Varanese</span></p></td></tr><tr class="c17"><td class="c9" colspan="1" rowspan="1"><p class="c0"><span class="c6 c7">Date:</span></p></td><td class="c18" colspan="2" rowspan="1"><p class="c0"><span class="c5">June 7</span><span class="c1">, 2018</span></p></td></tr><tr class="c15"><td class="c31" colspan="1" rowspan="1"><p class="c0 c13"><span class="c7 c6"></span></p></td><td class="c20" colspan="2" rowspan="1"><p class="c0 c13"><span class="c7 c6"></span></p></td></tr></tbody></table><p class="c2" id="h.t1qa23cuio3m"><span class="c7 c6"></span></p><p class="c0" id="h.t7kb4mixz8h9"><span class="c6">Overview</span></p><p class="c0" id="h.vfx6oxmm9gfq"><span class="c1">DeepTesla from MIT offers 10 videos of a Tesla Model S being driven on the highway, each with steering angle time stamped with each frame. The videos run at 30 FPS, which was sufficient for DeepTesla for being able to predict the steering angle from looking at a video stream using a Convolutional Neural Network (CNN). Five of the datasets are with the Tesla autopilot driving and the latter half is with a human driver. DeepTesla was able to get good results with their CNN, but we wanted to see if we could improve the error by adding in recurrence in the form of a 3D CNN.</span></p><p class="c0 c13" id="h.fl6ota2qnxi"><span class="c1"></span></p><p class="c0" id="h.stk0och7t972"><span class="c6">Breakdown of Work Done</span></p><ul class="c19 lst-kix_mxunidxk0446-0 start"><li class="c0 c21" id="h.a8ovjyu30rr"><span class="c1">Paul:</span></li></ul><ul class="c19 lst-kix_mxunidxk0446-1 start"><li class="c0 c8" id="h.wcrjgew5omfu"><span class="c1">Initial setup of converting videos to usable data. This took much longer than expected as the data was in no way formatted as cleanly as the mnist data.</span></li><li class="c0 c8" id="h.zgtj3di4po68"><span class="c1">Captured Video and Steering data on RC car using Nvidia Jetson TX2</span></li></ul><ul class="c19 lst-kix_mxunidxk0446-0"><li class="c0 c21" id="h.p8cgerdxmkyi"><span class="c1">Chris:</span></li></ul><ul class="c19 lst-kix_mxunidxk0446-1 start"><li class="c0 c8" id="h.tdvmfnvqnojz"><span class="c1">Creation of initial test 2D CNN model. </span></li><li class="c0 c8" id="h.4spkwx93gqhi"><span class="c1">Image visualization with saliency.</span></li></ul><ul class="c19 lst-kix_mxunidxk0446-0"><li class="c0 c21" id="h.q3tacqstuijp"><span class="c1">Journey:</span></li></ul><ul class="c19 lst-kix_mxunidxk0446-1 start"><li class="c0 c8" id="h.gei28z1o901b"><span class="c1">Creation of generator for sequences of images to reduce memory usage</span></li><li class="c0 c8" id="h.8qz5161tfswd"><span class="c1">3D CNN model</span></li></ul><p class="c0 c13" id="h.8jobslez5d1a"><span class="c1"></span></p><p class="c0" id="h.71twkln21aly"><span class="c7 c6">2D CNN with Saliency Maps</span></p><p class="c0" id="h.zcf633r89scl"><span class="c1">Our initial test 2D CNN performed much better than we expected, reaching an mse loss of around 1 after 2 epochs (which varied sometimes during training). The saliency maps show various things are picked up to determine the steering angle such as the lane lines, guard rails, and surprisingly enough-- the reflection of the vents!</span></p><p class="c0 c13" id="h.onfwmvvfw7i6"><span class="c1"></span></p><p class="c0" id="h.5kflmsvuf9mh"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 68.00px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 68.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c16 c29" id="h.yg4duspeww9t"><span class="c6">Figure 1. </span><span class="c1">Predicted: -3.5201 , Actual -2.0</span></p><p class="c2" id="h.9lx6g2mm6kay"><span class="c1"></span></p><p class="c0" id="h.arr5xk1lmpap"><span class="c7 c6">3D CNN model</span></p><p class="c0" id="h.1uq1skjizxm7"><span class="c1">The 3D CNN model resulted at best a mse loss of 13.4 steering angle degrees after three epochs. The most interesting thing about the 3D CNN model was the discovery that the final dense layer had to be the same shape as the number of sequences. For example if the 3D CNN had an input shape of (8, 105, 320, 3), the final dense layer had to be 8 to get Keras to run. The intended architecture was to have a single dense neuron predicting the steering angle. </span></p><p class="c0 c13" id="h.qyxam4ndvxis"><span class="c1"></span></p><p class="c0" id="h.iafxgzod0kii"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 232.00px; height: 183.00px;"><img alt="" src="images/image2.png" style="width: 263.00px; height: 198.90px; margin-left: -14.41px; margin-top: -11.45px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 276.45px; height: 163.50px;"><img alt="" src="images/image1.png" style="width: 276.45px; height: 163.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c14" id="h.tkudndig1rmh"><span class="c5">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 326.25px; height: 22.50px;"><img alt="" src="images/image3.png" style="width: 326.25px; height: 22.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0" id="h.jdz1vispmutc"><span class="c6">Figure 2. </span><span class="c5">Loss of Conv3D shows overfitting&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="c6">Figure 3. </span><span class="c1">&nbsp;Summary of the Conv3D model</span></p><p class="c0 c13" id="h.w7lzn4rx2rma"><span class="c1"></span></p><p class="c0" id="h.1uq1skjizxm7-1"><span class="c5">Another particularly interesting problem was the possibility of negative dimensions due to short sequence lengths. For example each Conv3D layer reduced the depth, length, and width by 2--but the MaxPooling3D resulted in a division by half! This required longer sequences, which resulted in GPU resources being exhausted. The solution then became using less layers, which caused the model to quickly over fit. Lastly, an LSTM layer was added after the Conv3D to make use of the temporal information. Unfortunately, the LSTM in Keras could not handle a 5D shape from the Conv3D. This suggests for situations like this, learning Tensorflow would be useful.</span></p><p class="c0 c13" id="h.lvxkvqc1njil"><span class="c7 c6"></span></p><p class="c0" id="h.vhw7nfxhkixu"><span class="c7 c6">Nvidia Jetson TX2 on RC car</span></p><p class="c0" id="h.75evt0hc6mfx"><span class="c1">Personal video and steering angles were collected using a mechanical engineering senior project RC car. The goal was to take what was learned from the MIT deepTesla dataset and apply it to a real world control problem. Videos were obtained, but time only allowed for a study in saliency maps.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 243.50px; height: 182.63px;"><img alt="" src="images/image4.jpg" style="width: 243.50px; height: 182.63px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c13" id="h.tdnjwjkq9je"><span class="c7 c6"></span></p><p class="c0" id="h.konc76rr80pf"><span class="c6">Figure 4. </span><span class="c1">&nbsp;RC car was used to log video and steering angles</span></p><p class="c2" id="h.8obi6m2spx8l"><span class="c1"></span></p><p class="c16" id="h.r0etb8xwi1ff"><span class="c6">Comments on Results</span></p><p class="c0" id="h.qo4wvptp4a3z"><span class="c1">The project got off to a slow start because of all of the unforeseen difficulties. Initially, separating all of the data from videos into images took some time to figure out. After that, we learned that working with 19GB of images was not an easy task, so we had to preprocess our images by compressing/cropping before moving them around. Then, even when we preprocessed them, our Nvidia Jetson TX2 and the school servers could not load the entire dataset at once, so we took some time looking into methods of only partially loading the dataset, but we instead settled on just processing the images even more--compressing them to an npz file. The 3D CNN eventually required a generator to take random sequences of videos. The team had better results with 2D Convolution, despite the the inclusion of temporal information. The team would suggest looking into Transfer Learning as further research suggested better results with using a pre-trained model such as ResNet50. </span></p><p class="c0 c13" id="h.leioo2v33nm2"><span class="c1"></span></p><p class="c0 c13" id="h.8jnvzns55rsg"><span class="c7 c6"></span></p><p class="c0 c13" id="h.ad84zwtubw7q"><span class="c7 c6"></span></p><p class="c0" id="h.z2r74s7ndaft"><span class="c7 c6">References</span></p><p class="c23"><span class="c5">[1] &ldquo;DeepTesla - End-to-End Steering Model.&rdquo; </span><span class="c5 c26">DeepTesla</span><span class="c1">, selfdrivingcars.mit.edu/deeptesla/.</span></p><p class="c23"><span class="c5">[2] &nbsp;Du, Shuyang, et al. &ldquo;Self-Driving Car Steering Angle Prediction Based on Image Recognition.&rdquo; </span><span class="c5 c26">Stanford</span><span class="c1">, pp. 1&ndash;9. </span></p></body></html>
